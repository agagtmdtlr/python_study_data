tokenisze_updata.py :
    크롤링 하여 저장한 updatae_csv.csv 파일을 토큰화하여 저장한다.
    파일명 : update_sentences.prepro
        word_embedding 에 사용할 argument data
    파일명 : update_tokenSet_v02.csv
        one_hot_encoding 에 사용할 data
    파일명 : update_word_csv_v02.csv
        여러가지에 사용할려고 저장

update_word2vec.py :
    정제한 문장을 word2vec에 활용하여 vector화(수치화 시키는 과정)
    one_hot_encoding은 단순히 frequency로 비교하여 각 단어간의 유사도 측정이 힘드므로
    집약행렬을 만든다. 방법 n-gram unsupervied algoritm을 사용한다.
    만들어낸 word matrix를 통해 각 단어별 코사인 유사도를 계산한다.
    코사인 유사도 행렬을 csv 파일로 저장한다.
    파일명 : update_similarity_matrix.csv

update_subset_keyword.py:
    모든 문장에 대한 one_hot_enocoding을 만든다.
    update_similarity_matrix 와 one_hot_enocoding_matrix 를 곱해서
    Wi * Si =>
            결과 Wi 단어에 대하여 Si에서 나타난 단어와의 유사도 점수를 총합한다.
            ex: Wi : 수박 / 여름 : 1 박쥐 : 0 물고기 : 1 담배 : 0 -> 수박|여름 : 0.12 + 수박|물고기 : 0.24
            수박과 이 문장의 유사도 : 0.36
            이런 식으로 모든 단에어 대한 문장 유사도를 구해본다.
            가장 높은게 이 문장의 키워드가 된당

update_keyword.py:
    update_subset_keyword.py 에서 구한 문장 유사도 score 행렬에서
    top10만 뽑아서 csv파일로 저장한다.
    파일명 : update_keyword_top10.csv
